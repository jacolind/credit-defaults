{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of problem\n",
    "\n",
    "Binary classificaiton problem. Predict y=1 for default. \n",
    "\n",
    "Variable names are hard to understand => use black box algorithm.\n",
    "\n",
    "we use auc because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "create another method for handling NAs. such as fill with mean, or fill with clustered mean. \n",
    "\n",
    "use cloud computing to make the script run faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basics :\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import*\n",
    "import datetime\n",
    "\n",
    "# custom plot :\n",
    "import itertools\n",
    "\n",
    "# scale data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "# save models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('dataset.csv', sep=\";\")\n",
    "vardescr = pd.read_csv('variabledescr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method A: fill NA with zeroes and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfp: all rows that have deafult=NA. this df is used for prediction.\n",
    "dfp = raw_data[pd.isnull(raw_data.default)]\n",
    "# crate dfm: all rows that have deafult=1 or 0. this df is used for modeling.\n",
    "dfm = raw_data[pd.notnull(raw_data.default)]\n",
    "\n",
    "# how many NA?\n",
    "total_na = dfm.isnull().sum().sum()\n",
    "total_cells =  dfm.count().sum()\n",
    "total_na / total_cells * 100\n",
    "\n",
    "# handle NA in dfm :\n",
    "dfm = dfm.fillna(0) # fill NA with zero\n",
    "\n",
    "# Select y for prediction and modeling\n",
    "yp = dfp['default']\n",
    "ym = dfm['default']\n",
    "ym.mean() #concl: 0.014 so very few deafults\n",
    "\n",
    "# Select X variables\n",
    "exclude = ['default', 'uuid', 'merchant_category', 'merchant_group', 'name_in_email']\n",
    "# .info() reveals these are dtype = object so exclude them to save time\n",
    "Xm = dfm.drop(exclude, axis=1)\n",
    "Xp = dfp.drop(exclude, axis=1).fillna(0)\n",
    "ym.shape[0] == Xm.shape[0]\n",
    "\n",
    "# standardize X\n",
    "scaler = StandardScaler().fit(Xm)\n",
    "Xm = scaler.transform(Xm)\n",
    "Xp = scaler.transform(Xp)\n",
    "\n",
    "# split into fit and tune\n",
    "Xf, Xt, yf, yt = train_test_split(Xm, ym, test_size=0.20, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method B: fill NA with column mean\n",
    "\n",
    "We impute the missing value (of variable j) for a certain observation (i,j) with the column mean (mean of j). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodb = False\n",
    "if methodb == True:\n",
    "    imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "    Xm = imp.fit_transform(Xm)\n",
    "# todo: continue writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method C: fill NA with clustered column mean\n",
    "\n",
    "Firstly we divide the data into clusters using k-means clustering. Then we impute the missing value for a certain row's column **j** simply by looking at which group this observation falls into and then replace the missing value with the that group's mean value for **j**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qq write this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and predict all models\n",
    "\n",
    "We use the following methods:\n",
    "\n",
    "- Logistic regression\n",
    "- K Nearest neighbour\n",
    "- Decision tree\n",
    "\n",
    "Using 5-fold crossvalidation, we see which model has the highest mean score. \n",
    "\n",
    "Which scoring should we use? Either roc_auc or recall. \n",
    "\n",
    "Argument for recall: Fraudulent transaction detector (positive class is \"fraud\"): Optimize for sensitivity because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)\n",
    "\n",
    "Argument for roc_auc: it is the standard method and selects a flexible model. If the AUC for one model is higher we can adjust the threshold in going form proba to classes...\n",
    "\n",
    "Chose roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of crossvalidation folds:\n",
    "cv = 5\n",
    "\n",
    "# select scoring metric\n",
    "scoring = 'roc_auc'\n",
    "#scoring = 'recall'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (reg)\n",
    "\n",
    "Explanation of what the hyperparameters measures:\n",
    "\n",
    "* Like the alpha parameter of lasso and ridge regularization, logistic regression also has a regularization parameter: C. C controls the inverse of the regularization strength, and this is what you will tune in this exercise. A large C can lead to an overfit model, while a small C can lead to an underfit model. `param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}`\n",
    "* penalty... qq write text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg\n",
      "Tuned Parameter: {'C': 0.43939705607607948, 'penalty': 'l1'}\n",
      "Tuned Accuracy: 0.8767331309761568\n"
     ]
    }
   ],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid_reg = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "reg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object\n",
    "reg_cv = GridSearchCV(reg, param_grid_reg, cv=cv, scoring=scoring)\n",
    "\n",
    "# Fit it to the training data\n",
    "load_reg = True# iff you run script for the first time, it should be False.\n",
    "# load model or fit\n",
    "if load_reg == True:\n",
    "    reg_cv = joblib.load(\"reg_cv.pkl\")\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    reg_cv.fit(Xf, yf)\n",
    "    t2 = datetime.datetime.now()\n",
    "    reg_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", reg_td)\n",
    "    # save model\n",
    "    joblib.dump(reg_cv, \"reg_cv.pkl\")\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"reg\")\n",
    "print(\"Tuned Parameter: {}\".format(reg_cv.best_params_))\n",
    "print(\"Tuned Accuracy: {}\".format(reg_cv.best_score_))\n",
    "# output: \n",
    "# params C = 0.44, penatly = 'l2' (with dfm)\n",
    "# params C = 0.4394, penalty = 'l1' (with dfm split into Xf Xt)\n",
    "# score 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n",
      "Tuned Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 5, 'min_samples_leaf': 38}\n",
      "Best score is 0.8284158379078223\n"
     ]
    }
   ],
   "source": [
    "# Setup the parameters\n",
    "param_dist = {\"max_depth\": [None, 10, 20, 30], # 30-50% av nr features\n",
    "              \"max_features\": [5, 10, 20, 30, Xm.shape[1]],\n",
    "              \"min_samples_leaf\": [1, 10, 20, 30, Xm.shape[1]],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "# Instantiate the GridSearchCV() object: tree_cv\n",
    "tree_cv = GridSearchCV(tree, param_dist, cv=cv, scoring=scoring, n_jobs = -1)\n",
    "\n",
    "# Fit it to the data\n",
    "load_tree = True\n",
    "if load_tree == True:\n",
    "    tree_cv = joblib.load('tree_cv.pkl')\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    tree_cv.fit(Xf, yf)\n",
    "    t2 = datetime.datetime.now()\n",
    "    tree_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", tree_td)\n",
    "    # save model\n",
    "    joblib.dump(tree_cv, \"tree_cv.pkl\")\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"tree\")\n",
    "print(\"Tuned Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "# output: \n",
    "# params are 'criterion': 'gini', 'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 38}\n",
    "# score 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest neighbour (knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I WONT EVEN USE KNN BECAUSE I HAPPEN TO KNOW A PRIORI IT TAKE SLONG TIME AND IS BAD, SO I DONT WANT TO WASTE MY TIME RIGHT NOW. MAYBE LATER WHEN PRESENTING A NICE SCRIPT. SO I LEAVE THE CODE AS-IS FROM THE default1_20171129.IPYNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned parameters: {'n_neighbors': 7}\n",
      "Best score is 0.6850930867004873\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# set up parameters\n",
    "k_range = list(range(4, 8))\n",
    "param_grid = dict(n_neighbors = k_range)\n",
    "# instantiate\n",
    "knn = KNeighborsClassifier()\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv=cv, scoring=scoring, n_jobs = -1)\n",
    "# fit\n",
    "load_knn = True\n",
    "if load_knn == True:\n",
    "    knn_cv = joblib.load('knn_cv.pkl')\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    knn_cv.fit(Xm, ym)  # took a long time to run - 1 hour\n",
    "    t2 = datetime.datetime.now()\n",
    "    knn_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", knn_td)\n",
    "# examine the best model\n",
    "print(\"Tuned parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Best score is {}\".format(knn_cv.best_score_))\n",
    "print(knn_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "We define best model as highest AUC. Rule of thumb says an AUC > 0.80 is to be considered very good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 0.876733130976\n",
      "tree 0.828415837908\n",
      "knn 0.6850930867\n",
      "Winning model is: reg\n",
      "reg details: LogisticRegression(C=0.43939705607607948, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"reg\", reg_cv.best_score_)     \n",
    "print(\"tree\", tree_cv.best_score_)\n",
    "print(\"knn\", knn_cv.best_score_)\n",
    "print(\"Winning model is: reg\")\n",
    "print(\"reg details:\", reg_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare classificaiton\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot roc curve of winning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888302823525\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9bdae7ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "penalty = 'l1'\n",
    "C = 0.4394\n",
    "reg = LogisticRegression(C = C, penalty = penalty)\n",
    "y_pred_score = reg.fit(Xf, yf).decision_function(Xt)\n",
    "fpr, tpr, thresholds = roc_curve(yt, y_pred_score)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(roc_auc) #is higher than before because now we have entire Xf and before we had cv=5 of Xf\n",
    "\n",
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold\n",
    "\n",
    "We now have a winning model. Even though the task was to present probabilities, the task in real life is to predict 0 or 1 and act based on that. So we will create a model that is best for this purpose. Given this purpose, we will change the threshold for predict class=1 based on the predicted proba. By default threshold=0.5 but what if being more suspoicious against users and setting a lower threshold of say 0.4 makes the number of defaults lower? \n",
    "\n",
    "We will take the winning (highest auc) model from the \"fit set\" (Xf, yf) and apply it to the \"tune set\" (Xt, yt). Based on the Xt our model predicts proba. These proba are turned into classifications via a threshold that we vary.  We plot one confusion matrix per threshold. Based on the confusion matrix we chose the threshold that balance FP and FN in a way we believe is optimal for the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f819017572d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# code from sklearn documentation\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from the kaggle page\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit, predict, and create confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall & recall 1.0  &  0.019\n",
      "[[ 4450 13291]\n",
      " [    0   255]]\n",
      "Recall & recall 0.969  &  0.027\n",
      "[[8942 8799]\n",
      " [   8  247]]\n",
      "Recall & recall 0.922  &  0.037\n",
      "[[11596  6145]\n",
      " [   20   235]]\n",
      "Recall & recall 0.808  &  0.056\n",
      "[[14300  3441]\n",
      " [   49   206]]\n",
      "Recall & recall 0.451  &  0.14\n",
      "[[17037   704]\n",
      " [  140   115]]\n",
      "Recall & recall 0.243  &  0.204\n",
      "[[17499   242]\n",
      " [  193    62]]\n",
      "Recall & recall 0.098  &  0.25\n",
      "[[17666    75]\n",
      " [  230    25]]\n",
      "Recall & recall 0.071  &  0.321\n",
      "[[17703    38]\n",
      " [  237    18]]\n",
      "Recall & recall 0.055  &  0.4\n",
      "[[17720    21]\n",
      " [  241    14]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = reg.predict_proba(Xt)\n",
    "\n",
    "thresholds = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1,0.2,0.3,0.4]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "j = 1\n",
    "for thresh in thresholds:\n",
    "    # predict y=1 if proba > threshold \n",
    "    y_pred_class = y_pred_proba[:,1] > thresh\n",
    "    \n",
    "    plt.subplot(3,3,j)\n",
    "    j += 1\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(yt, y_pred_class)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    #print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "    print(\"Recall & recall\", np.round(recall_score(yt, y_pred_class), 3), \n",
    "          \" & \",\n",
    "         np.round(precision_score(yt, y_pred_class), 3)\n",
    "         )\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, title='Threshold > %s'%thresh) \n",
    "    \n",
    "    # plot regular\n",
    "    print(confusion_matrix(yt, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions\n",
    "\n",
    "We take the model with the highest AUC above and use that to make prediction on `Xp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate model with optimal parameters\n",
    "logreg = LogisticRegression(C = 0.44, penalty = 'l2')\n",
    "# fit on entire modeling dataframe \n",
    "logreg.fit(Xm, ym)\n",
    "# predict \n",
    "predictions = logreg.predict_proba(Xp)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred uuid\n",
      "0  0.013024  NaN\n",
      "1  0.014024  NaN\n",
      "2  0.000119  NaN\n",
      "3  0.032147  NaN\n",
      "4  0.078474  NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions and IDs to csv\n",
    "predictions = pd.Series(predictions, name = \"pred\")\n",
    "IDlist = pd.Series(dfp['uuid'])\n",
    "#predictions_IDlist = pd.concat([predictions, IDlist], axis=1, ignore_index=True)\n",
    "predictions_IDlist = pd.concat([predictions, IDlist], axis=1)\n",
    "print(predictions_IDlist.head())\n",
    "len(predictions), len(dfp.uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f152f6688f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work\n",
    "\n",
    "build a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "qq change the code below. it is for neural netw with train test split, i want cv=5. and roc_auc not accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e30ac9ba23e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# In[19]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras for neural networks:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy import*\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(Xm, Ym, random_state=4)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=25, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=64)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
