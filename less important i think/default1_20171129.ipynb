{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of problem\n",
    "\n",
    "Binary classificaiton problem. Predict y=1 for default. \n",
    "\n",
    "Variable names are hard to understand => use black box algorithm.\n",
    "\n",
    "we use auc because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "create another method for handling NAs. such as fill with mean, or fill with clustered mean. \n",
    "\n",
    "use cloud computing to make the script run faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basics :\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import*\n",
    "import datetime\n",
    "\n",
    "# scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# save models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('dataset.csv', sep=\";\")\n",
    "vardescr = pd.read_csv('variabledescr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method A: fill NA with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create dfp: all rows that have deafult=NA. this df is used for prediction.\n",
    "dfp = raw_data[pd.isnull(raw_data.default)]\n",
    "# crate dfm: all rows that have deafult=1 or 0. this df is used for modeling.\n",
    "dfm = raw_data[pd.notnull(raw_data.default)]\n",
    "\n",
    "# how many NA?\n",
    "total_na = dfm.isnull().sum().sum()\n",
    "total_cells =  dfm.count().sum()\n",
    "total_na / total_cells * 100\n",
    "\n",
    "# handle NA in dfm :\n",
    "dfm = dfm.fillna(0) # fill NA with zero\n",
    "\n",
    "# Select y for prediction and modeling\n",
    "yp = dfp['default'].as_matrix()\n",
    "ym = dfm['default'].as_matrix()\n",
    "ym.mean() #concl: 0.014 so very few deafults\n",
    "\n",
    "# Select X variables\n",
    "exclude = ['default', 'uuid', 'merchant_category', 'merchant_group', 'name_in_email']\n",
    "# .info() reveals these are dtype = object so exclude them to save time\n",
    "Xm = dfm.drop(exclude, axis=1).as_matrix()\n",
    "Xp = dfp.drop(exclude, axis=1).fillna(0).as_matrix()\n",
    "ym.shape[0] == Xm.shape[0]\n",
    "\n",
    "# standardize X\n",
    "scaler = StandardScaler().fit(Xm)\n",
    "Xm = scaler.transform(Xm)\n",
    "Xp = scaler.transform(Xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method B: fill NA with clustered column mean\n",
    "\n",
    "Firstly we divide the data into clusters using k-means clustering. Then we impute the missing value for a certain row's column **j** simply by looking at which group this observation falls into and then replace the missing value with the that group's mean value for **j**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qq write this code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and predict all models\n",
    "\n",
    "We the following methods:\n",
    "\n",
    "- Logistic regression\n",
    "- K Nearest neighbour\n",
    "- Decision tree\n",
    "\n",
    "Using 5-fold crossvalidation, we see which model has the highest mean score. \n",
    "\n",
    "Which scoring should we use? Either roc_auc or recall. \n",
    "\n",
    "Argument for recall: Fraudulent transaction detector (positive class is \"fraud\"): Optimize for sensitivity because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)\n",
    "\n",
    "Argument for roc_auc: it is the standard method and selects a flexible model. If the AUC for one model is higher we can adjust the threshold in going form proba to classes...\n",
    "\n",
    "Chose roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of crossvalidation folds:\n",
    "cv = 5\n",
    "\n",
    "# select scoring metric\n",
    "scoring = 'roc_auc'\n",
    "#scoring = 'recall'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (reg)\n",
    "\n",
    "Explanation of what the hyperparameters measures:\n",
    "\n",
    "* Like the alpha parameter of lasso and ridge regularization, logistic regression also has a regularization parameter: C. C controls the inverse of the regularization strength, and this is what you will tune in this exercise. A large C can lead to an overfit model, while a small C can lead to an underfit model. `param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}`\n",
    "* penalty... qq write text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg\n",
      "Tuned Parameter: {'C': 0.43939705607607948, 'penalty': 'l2'}\n",
      "Tuned Accuracy: 0.8758995109614676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-05,   8.48343e-05,   7.19686e-04,   6.10540e-03,\n",
       "         5.17947e-02,   4.39397e-01,   3.72759e+00,   3.16228e+01,\n",
       "         2.68270e+02,   2.27585e+03,   1.93070e+04,   1.63789e+05,\n",
       "         1.38950e+06,   1.17877e+07,   1.00000e+08]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid_reg = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "reg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object\n",
    "reg_cv = GridSearchCV(reg, param_grid_reg, cv=cv, scoring=scoring)\n",
    "\n",
    "# Fit it to the training data\n",
    "load_reg = True # iff you run script for the first time, it should be False.\n",
    "# load model or fit\n",
    "if load_reg == True:\n",
    "    reg_cv = joblib.load(\"reg_cv.pkl\")\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    reg_cv.fit(Xm, ym)\n",
    "    t2 = datetime.datetime.now()\n",
    "    reg_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", reg_td)\n",
    "    # save model\n",
    "    joblib.dump(reg_cv, \"reg_cv.pkl\")\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"reg\")\n",
    "print(\"Tuned Parameter: {}\".format(reg_cv.best_params_))\n",
    "print(\"Tuned Accuracy: {}\".format(reg_cv.best_score_))\n",
    "# output: \n",
    "# params C = 0.44, penatly = 'l2' \n",
    "# score 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n",
      "Tuned Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 38}\n",
      "Best score is 0.8404864819562125\n"
     ]
    }
   ],
   "source": [
    "# Setup the parameters\n",
    "param_dist = {\"max_depth\": [None, 10, 20, 30], # 30-50% av nr features\n",
    "              \"max_features\": [5, 10, 20, 30, Xm.shape[1]],\n",
    "              \"min_samples_leaf\": [1, 10, 20, 30, Xm.shape[1]],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "# Instantiate the GridSearchCV() object: tree_cv\n",
    "tree_cv = GridSearchCV(tree, param_dist, cv=cv, scoring=scoring, n_jobs = -1)\n",
    "\n",
    "# Fit it to the data\n",
    "load_tree = True\n",
    "if load_tree == True:\n",
    "    tree_cv = joblib.load('tree_cv.pkl')\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    tree_cv.fit(Xm, ym)\n",
    "    t2 = datetime.datetime.now()\n",
    "    tree_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", tree_td)\n",
    "    # save model\n",
    "    joblib.dump(tree_cv, \"tree_cv.pkl\")\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"tree\")\n",
    "print(\"Tuned Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "# output: \n",
    "# params are 'criterion': 'gini', 'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 38}\n",
    "# score 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest neighbour (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned parameters: {'n_neighbors': 7}\n",
      "Best score is 0.6850930867004873\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# set up parameters\n",
    "k_range = list(range(4, 8))\n",
    "param_grid = dict(n_neighbors = k_range)\n",
    "# instantiate\n",
    "knn = KNeighborsClassifier()\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv=cv, scoring=scoring, n_jobs = -1)\n",
    "# fit\n",
    "load_knn = True\n",
    "if load_knn == True:\n",
    "    knn_cv = joblib.load('knn_cv.pkl')\n",
    "else:\n",
    "    t1 = datetime.datetime.now()\n",
    "    knn_cv.fit(Xm, ym)  # took a long time to run - 1 hour\n",
    "    t2 = datetime.datetime.now()\n",
    "    knn_td = t2-t1\n",
    "    print(\"Fitting time H:MM:SS \", knn_td)\n",
    "# examine the best model\n",
    "print(\"Tuned parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Best score is {}\".format(knn_cv.best_score_))\n",
    "print(knn_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "qq change the code below. it is for neural netw with train test split, i want cv=5. and roc_auc not accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e30ac9ba23e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# In[19]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras for neural networks:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy import*\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(Xm, Ym, random_state=4)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=25, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=64)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "We define best model as highest AUC. Rule of thumb says an AUC > 0.80 is to be considered very good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 0.875899510961\n",
      "tree 0.840486481956\n",
      "knn 0.6850930867\n",
      "Winning model is: reg\n",
      "reg details: LogisticRegression(C=0.43939705607607948, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"reg\", reg_cv.best_score_)     \n",
    "print(\"tree\", tree_cv.best_score_)\n",
    "print(\"knn\", knn_cv.best_score_)\n",
    "print(\"Winning model is: reg\")\n",
    "print(\"reg details:\", reg_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare classificaiton\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions\n",
    "\n",
    "We take the model with the highest AUC above and use that to make prediction on `Xp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate model with optimal parameters\n",
    "logreg = LogisticRegression(C = 0.44, penalty = 'l2')\n",
    "# fit on entire modeling dataframe \n",
    "logreg.fit(Xm, ym)\n",
    "# predict \n",
    "predictions = logreg.predict_proba(Xp)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pred uuid\n",
      "0  0.013024  NaN\n",
      "1  0.014024  NaN\n",
      "2  0.000119  NaN\n",
      "3  0.032147  NaN\n",
      "4  0.078474  NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions and IDs to csv\n",
    "predictions = pd.Series(predictions, name = \"pred\")\n",
    "IDlist = pd.Series(dfp['uuid'])\n",
    "#predictions_IDlist = pd.concat([predictions, IDlist], axis=1, ignore_index=True)\n",
    "predictions_IDlist = pd.concat([predictions, IDlist], axis=1)\n",
    "print(predictions_IDlist.head())\n",
    "len(predictions), len(dfp.uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f152f6688f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
